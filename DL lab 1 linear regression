
!pip install scikit-learn==1.1.2

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_boston
import tensorflow.compat.v2 as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
import keras
from keras.layers import Dense, Activation,Dropout
from keras.models import Sequential
import warnings
warnings.filterwarnings("ignore")

# Loading Data
#boston = load_boston()

#from google.colab import drive
#drive.mount('/content/drive')


from google.colab import files
uploaded = files.upload()


data = pd.DataFrame(boston.data)

data.columns = boston.feature_names
data['PRICE'] = boston.target
data.head()

# Data Exploration
print(data.head())

print(data.shape)

print(data.dtypes)

print(data.isnull().sum())

print(data.describe())

# Data Visualization
sns.displot(data.PRICE)


correlation = data.corr()
correlation.loc['PRICE']


fig,axes = plt.subplots(figsize=(15,12))
sns.heatmap(correlation,square = True,annot = True)

# Splitting Data into testing and training data
X = data.iloc[:,:-1]
y= data.PRICE
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 4)


# Normalizing the data
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test # Model=Building sc.transform(X_test)

# Model Building
model = Sequential()
model.add(Dense(128,activation = 'relu',input_dim =13))
model.add(Dense(64,activation = 'relu'))
model.add(Dense(32,activation = 'relu'))
model.add(Dense(16,activation = 'relu'))
model.add(Dense(1))
model.compile(optimizer = 'adam',loss = 'mean_squared_error')
model.summary()


print(X_train.shape)
print(X_train.shape[1])


# Fitting the data to the model
model.fit(X_train, y_train, epochs = 100)

# Evaluating the model
y_pred = model.predict(X_test)
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print("R2 Score =", r2)
print("RMSE Score =", rmse)

# Reshape y_pred
y_pred = np.squeeze(y_pred)

# Calculate Mean Absolute Error
mae = np.mean(np.abs(y_pred - y_test))
print("Mean Absolute Error:", mae)


# Evaluating  the model
y_pred = model.predict(X_test)
r2 = r2_score(y_test, y_pred)
rmse = (np.sqrt(mean_squared_error(y_test, y_pred)))
print("R2 Score = ", r2)
print("RMSE Score = ", rmse)


# Reshape y_pred
y_pred = np.squeeze(y_pred)

# Calculate Mean Absolute Error
mae = np.mean(np.abs(y_pred - y_test))
print("Mean Absolute Error:", mae)


# Scatter plot of predicted vs. actual prices
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.5, label='Data Points')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label='Perfect Prediction Line')
plt.title('Predicted vs. Actual Prices')
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.legend()
plt.text(10, 45, 'Actual Values', color='blue', fontsize=10, ha='center')
plt.text(45, 10, 'Predicted Values', color='blue', fontsize=10, rotation=90, va='center')
plt.show()

     

